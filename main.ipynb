{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Problem 3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-nestcDKHQT"
      },
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Dropout, Activation\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uweTgj5zKU2b"
      },
      "source": [
        "p = 7\n",
        "n = 10000\n",
        "inputs = []\n",
        "outputs = []\n",
        "\n",
        "def f(x,y):\n",
        "  return (x-y)%p\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for i in range(n):\n",
        "  x = np.random.randint(0, p)\n",
        "  y = np.random.randint(0, p)\n",
        "  inputs.append([x,y])\n",
        "  outputs.append([f(x,y)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15ryrvihoh_9"
      },
      "source": [
        "p = 7\n",
        "n = 10000\n",
        "inputs = []\n",
        "outputs = []\n",
        "\n",
        "def g(seq):\n",
        "  if len(seq)<5:\n",
        "    seq += [0]*(5-len(seq))\n",
        "  return seq[0]-seq[1]+seq[2]-seq[3]+seq[4]\n",
        "for i in range(n):\n",
        "  l = np.random.randint(0,6)\n",
        "  temp = [np.random.randint(0, p) for j in range(l)]\n",
        "  inputs.append(temp)\n",
        "  outputs.append(g(temp))\n",
        "\n",
        "# print(inputs)\n",
        "# print(outputs)\n",
        "\n",
        "# print(g([0,2,0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAicP_RlOX9M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08c627d5-22e0-4cea-eec8-2c09dac32b23"
      },
      "source": [
        "X = np.reshape(inputs, (len(inputs), len(inputs[0]), 1))\n",
        "X = X/p # normalize\n",
        "y = np_utils.to_categorical(outputs)\n",
        "\n",
        "model = Sequential()\n",
        "# Note: all LSTM layers except the last must have 'return_sequences=True'\n",
        "model.add(LSTM(128, input_shape=(X.shape[1], 1), return_sequences=True))\n",
        "model.add(LSTM(64, return_sequences=True))\n",
        "model.add(LSTM(32, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(16, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(16, return_sequences=True))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(LSTM(8))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['acc'])\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(X, y, epochs=50, batch_size=64,\\\n",
        "                    verbose=2, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_65 (LSTM)               (None, 5, 128)            66560     \n",
            "_________________________________________________________________\n",
            "lstm_66 (LSTM)               (None, 5, 64)             49408     \n",
            "_________________________________________________________________\n",
            "lstm_67 (LSTM)               (None, 5, 32)             12416     \n",
            "_________________________________________________________________\n",
            "dropout_35 (Dropout)         (None, 5, 32)             0         \n",
            "_________________________________________________________________\n",
            "lstm_68 (LSTM)               (None, 5, 16)             3136      \n",
            "_________________________________________________________________\n",
            "dropout_36 (Dropout)         (None, 5, 16)             0         \n",
            "_________________________________________________________________\n",
            "lstm_69 (LSTM)               (None, 5, 16)             2112      \n",
            "_________________________________________________________________\n",
            "dropout_37 (Dropout)         (None, 5, 16)             0         \n",
            "_________________________________________________________________\n",
            "lstm_70 (LSTM)               (None, 8)                 800       \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 19)                171       \n",
            "=================================================================\n",
            "Total params: 134,603\n",
            "Trainable params: 134,603\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "125/125 - 13s - loss: 2.7161 - acc: 0.1685 - val_loss: 2.5374 - val_acc: 0.2610\n",
            "Epoch 2/50\n",
            "125/125 - 3s - loss: 2.5331 - acc: 0.2590 - val_loss: 2.4588 - val_acc: 0.2610\n",
            "Epoch 3/50\n",
            "125/125 - 3s - loss: 2.3494 - acc: 0.2590 - val_loss: 2.2471 - val_acc: 0.2610\n",
            "Epoch 4/50\n",
            "125/125 - 3s - loss: 2.2317 - acc: 0.2663 - val_loss: 2.1833 - val_acc: 0.2790\n",
            "Epoch 5/50\n",
            "125/125 - 3s - loss: 2.1747 - acc: 0.2834 - val_loss: 2.1231 - val_acc: 0.2835\n",
            "Epoch 6/50\n",
            "125/125 - 3s - loss: 2.1271 - acc: 0.3022 - val_loss: 2.0814 - val_acc: 0.3115\n",
            "Epoch 7/50\n",
            "125/125 - 3s - loss: 1.9938 - acc: 0.3388 - val_loss: 1.8526 - val_acc: 0.3915\n",
            "Epoch 8/50\n",
            "125/125 - 3s - loss: 1.7981 - acc: 0.4055 - val_loss: 1.6784 - val_acc: 0.4745\n",
            "Epoch 9/50\n",
            "125/125 - 3s - loss: 1.6598 - acc: 0.4582 - val_loss: 1.5516 - val_acc: 0.5495\n",
            "Epoch 10/50\n",
            "125/125 - 3s - loss: 1.5288 - acc: 0.5175 - val_loss: 1.4048 - val_acc: 0.5440\n",
            "Epoch 11/50\n",
            "125/125 - 3s - loss: 1.3748 - acc: 0.5456 - val_loss: 1.2475 - val_acc: 0.6275\n",
            "Epoch 12/50\n",
            "125/125 - 3s - loss: 1.2283 - acc: 0.6010 - val_loss: 1.1113 - val_acc: 0.6545\n",
            "Epoch 13/50\n",
            "125/125 - 3s - loss: 1.1793 - acc: 0.6392 - val_loss: 1.0507 - val_acc: 0.7215\n",
            "Epoch 14/50\n",
            "125/125 - 3s - loss: 1.0703 - acc: 0.6783 - val_loss: 0.9288 - val_acc: 0.7610\n",
            "Epoch 15/50\n",
            "125/125 - 3s - loss: 0.9790 - acc: 0.7132 - val_loss: 0.8690 - val_acc: 0.7700\n",
            "Epoch 16/50\n",
            "125/125 - 3s - loss: 0.9641 - acc: 0.7055 - val_loss: 1.0801 - val_acc: 0.6100\n",
            "Epoch 17/50\n",
            "125/125 - 3s - loss: 0.8937 - acc: 0.7309 - val_loss: 0.7640 - val_acc: 0.7900\n",
            "Epoch 18/50\n",
            "125/125 - 3s - loss: 0.8177 - acc: 0.7556 - val_loss: 0.7221 - val_acc: 0.7855\n",
            "Epoch 19/50\n",
            "125/125 - 3s - loss: 0.7800 - acc: 0.7675 - val_loss: 0.6708 - val_acc: 0.8020\n",
            "Epoch 20/50\n",
            "125/125 - 3s - loss: 0.7467 - acc: 0.7729 - val_loss: 0.6532 - val_acc: 0.7970\n",
            "Epoch 21/50\n",
            "125/125 - 3s - loss: 0.7065 - acc: 0.7835 - val_loss: 0.6216 - val_acc: 0.8070\n",
            "Epoch 22/50\n",
            "125/125 - 3s - loss: 0.6790 - acc: 0.8045 - val_loss: 0.5594 - val_acc: 0.8665\n",
            "Epoch 23/50\n",
            "125/125 - 3s - loss: 0.6753 - acc: 0.8030 - val_loss: 0.5285 - val_acc: 0.8675\n",
            "Epoch 24/50\n",
            "125/125 - 3s - loss: 0.5924 - acc: 0.8404 - val_loss: 0.4873 - val_acc: 0.8920\n",
            "Epoch 25/50\n",
            "125/125 - 3s - loss: 0.5651 - acc: 0.8489 - val_loss: 0.4570 - val_acc: 0.8960\n",
            "Epoch 26/50\n",
            "125/125 - 3s - loss: 0.5304 - acc: 0.8627 - val_loss: 0.4242 - val_acc: 0.9040\n",
            "Epoch 27/50\n",
            "125/125 - 3s - loss: 0.5151 - acc: 0.8618 - val_loss: 0.4242 - val_acc: 0.9020\n",
            "Epoch 28/50\n",
            "125/125 - 3s - loss: 0.5099 - acc: 0.8583 - val_loss: 0.4505 - val_acc: 0.8875\n",
            "Epoch 29/50\n",
            "125/125 - 3s - loss: 0.4661 - acc: 0.8750 - val_loss: 0.3771 - val_acc: 0.9125\n",
            "Epoch 30/50\n",
            "125/125 - 3s - loss: 0.4652 - acc: 0.8701 - val_loss: 0.3567 - val_acc: 0.9145\n",
            "Epoch 31/50\n",
            "125/125 - 3s - loss: 0.4331 - acc: 0.8856 - val_loss: 0.4394 - val_acc: 0.8900\n",
            "Epoch 32/50\n",
            "125/125 - 3s - loss: 0.4260 - acc: 0.8821 - val_loss: 0.3718 - val_acc: 0.9070\n",
            "Epoch 33/50\n",
            "125/125 - 3s - loss: 0.4011 - acc: 0.8900 - val_loss: 0.3232 - val_acc: 0.9185\n",
            "Epoch 34/50\n",
            "125/125 - 3s - loss: 0.4192 - acc: 0.8794 - val_loss: 0.3214 - val_acc: 0.9170\n",
            "Epoch 35/50\n",
            "125/125 - 3s - loss: 0.3868 - acc: 0.8901 - val_loss: 0.2951 - val_acc: 0.9320\n",
            "Epoch 36/50\n",
            "125/125 - 3s - loss: 0.3717 - acc: 0.8924 - val_loss: 0.2866 - val_acc: 0.9220\n",
            "Epoch 37/50\n",
            "125/125 - 3s - loss: 0.3577 - acc: 0.8996 - val_loss: 0.2758 - val_acc: 0.9305\n",
            "Epoch 38/50\n",
            "125/125 - 3s - loss: 0.3380 - acc: 0.9049 - val_loss: 0.2806 - val_acc: 0.9310\n",
            "Epoch 39/50\n",
            "125/125 - 3s - loss: 0.3263 - acc: 0.9072 - val_loss: 0.2526 - val_acc: 0.9360\n",
            "Epoch 40/50\n",
            "125/125 - 3s - loss: 0.3530 - acc: 0.8919 - val_loss: 0.2500 - val_acc: 0.9285\n",
            "Epoch 41/50\n",
            "125/125 - 3s - loss: 0.3085 - acc: 0.9116 - val_loss: 0.2483 - val_acc: 0.9345\n",
            "Epoch 42/50\n",
            "125/125 - 3s - loss: 0.3049 - acc: 0.9124 - val_loss: 0.2646 - val_acc: 0.9250\n",
            "Epoch 43/50\n",
            "125/125 - 3s - loss: 0.3050 - acc: 0.9062 - val_loss: 0.2541 - val_acc: 0.9260\n",
            "Epoch 44/50\n",
            "125/125 - 3s - loss: 0.2978 - acc: 0.9112 - val_loss: 0.2307 - val_acc: 0.9295\n",
            "Epoch 45/50\n",
            "125/125 - 3s - loss: 0.3011 - acc: 0.9086 - val_loss: 0.2261 - val_acc: 0.9440\n",
            "Epoch 46/50\n",
            "125/125 - 3s - loss: 0.3173 - acc: 0.9021 - val_loss: 0.2232 - val_acc: 0.9395\n",
            "Epoch 47/50\n",
            "125/125 - 3s - loss: 0.2815 - acc: 0.9141 - val_loss: 0.2111 - val_acc: 0.9435\n",
            "Epoch 48/50\n",
            "125/125 - 3s - loss: 0.2964 - acc: 0.9068 - val_loss: 0.2089 - val_acc: 0.9355\n",
            "Epoch 49/50\n",
            "125/125 - 3s - loss: 0.2941 - acc: 0.9085 - val_loss: 0.2829 - val_acc: 0.9175\n",
            "Epoch 50/50\n",
            "125/125 - 3s - loss: 0.2661 - acc: 0.9231 - val_loss: 0.1955 - val_acc: 0.9470\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAdW9bSixG5m",
        "outputId": "8e211603-f874-4cee-f3ab-9f44218bf6cf"
      },
      "source": [
        "# text prediction\n",
        "\n",
        "from urllib.request import urlopen\n",
        "import re\n",
        "\n",
        "url = \"https://www.gutenberg.org/files/1661/1661-0.txt\"\n",
        "file = urlopen(url)\n",
        "text = file.read().decode(\"utf-8\").lower()\n",
        "\n",
        "# preprocess the text to remove punctuation, non-alphabetic char, multiple spaces\n",
        "text = re.sub('[^a-zA-Z]', ' ', text)\n",
        "text = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', text)\n",
        "text = re.sub(r'\\s+', ' ', text)\n",
        "\n",
        "\n",
        "\n",
        "print('# of total char: ', len(text))\n",
        "unique_char = sorted(list(set(text)))\n",
        "print('# of unique char: ', len(unique_char))\n",
        "\n",
        "#to map unique characters to integers\n",
        "i2c = {}\n",
        "c2i = {}\n",
        "for idx,char in enumerate(unique_char):\n",
        "  i2c[idx] = char\n",
        "  c2i[char] = idx\n",
        "\n",
        "#define input and output dataset by chunking our text\n",
        "\n",
        "#each subsentence has k characters\n",
        "k = 50\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(text) - k, step):\n",
        "    sentences.append(text[i: i + k])\n",
        "    next_chars.append(text[i + k])\n",
        "#convert the information to bool represented array\n",
        "\n",
        "x = np.zeros((len(sentences), k, len(unique_char)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences), len(unique_char)), dtype=np.bool)\n",
        "\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for c, char in enumerate(sentence):\n",
        "        x[i, c, c2i[char]] = 1\n",
        "    y[i, c2i[next_chars[i]]] = 1\n",
        "\n",
        "# print(x)\n",
        "# print(y)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# of total char:  543516\n",
            "# of unique char:  27\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31CRcriNy6Az",
        "outputId": "f924d54a-af59-4115-b2da-a0f6c592bea0"
      },
      "source": [
        "# print(i2c)\n",
        "# print(x[10][5])\n",
        "# print(y[10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[False False False False False False  True False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False]\n",
            "[False False False False False  True False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkA19oSk4yQ7",
        "outputId": "48b3b204-95f8-4658-f0e6-48663823ff98"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(k, len(unique_char)), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics = ['acc'])\n",
        "\n",
        "#This part is not original!! Reference to https://machinelearningmastery.com/text-generation-lstm-recurrent-neural-networks-python-keras/\n",
        "# define the checkpoint\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]\n",
        "# fit the model\n",
        "history = model.fit(x, y, epochs=10, batch_size=128, callbacks=callbacks_list,validation_split=0.2)\n",
        "\n",
        "# history = model.fit(x, y, batch_size=128, epochs=5,validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1133/1133 [==============================] - 398s 348ms/step - loss: 2.5939 - acc: 0.2525 - val_loss: 2.0386 - val_acc: 0.3955\n",
            "\n",
            "Epoch 00001: loss improved from inf to 2.33042, saving model to weights-improvement-01-2.3304.hdf5\n",
            "Epoch 2/10\n",
            "1133/1133 [==============================] - 393s 347ms/step - loss: 1.9792 - acc: 0.4074 - val_loss: 1.8402 - val_acc: 0.4412\n",
            "\n",
            "Epoch 00002: loss improved from 2.33042 to 1.93230, saving model to weights-improvement-02-1.9323.hdf5\n",
            "Epoch 3/10\n",
            "1133/1133 [==============================] - 392s 346ms/step - loss: 1.8151 - acc: 0.4475 - val_loss: 1.7408 - val_acc: 0.4709\n",
            "\n",
            "Epoch 00003: loss improved from 1.93230 to 1.79146, saving model to weights-improvement-03-1.7915.hdf5\n",
            "Epoch 4/10\n",
            "1133/1133 [==============================] - 392s 346ms/step - loss: 1.7237 - acc: 0.4703 - val_loss: 1.6811 - val_acc: 0.4862\n",
            "\n",
            "Epoch 00004: loss improved from 1.79146 to 1.70676, saving model to weights-improvement-04-1.7068.hdf5\n",
            "Epoch 5/10\n",
            "1133/1133 [==============================] - 391s 345ms/step - loss: 1.6535 - acc: 0.4908 - val_loss: 1.6320 - val_acc: 0.5048\n",
            "\n",
            "Epoch 00005: loss improved from 1.70676 to 1.64127, saving model to weights-improvement-05-1.6413.hdf5\n",
            "Epoch 6/10\n",
            "1133/1133 [==============================] - 390s 345ms/step - loss: 1.5939 - acc: 0.5077 - val_loss: 1.5956 - val_acc: 0.5112\n",
            "\n",
            "Epoch 00006: loss improved from 1.64127 to 1.59078, saving model to weights-improvement-06-1.5908.hdf5\n",
            "Epoch 7/10\n",
            "1133/1133 [==============================] - 391s 345ms/step - loss: 1.5511 - acc: 0.5207 - val_loss: 1.5710 - val_acc: 0.5178\n",
            "\n",
            "Epoch 00007: loss improved from 1.59078 to 1.55211, saving model to weights-improvement-07-1.5521.hdf5\n",
            "Epoch 8/10\n",
            "1133/1133 [==============================] - 391s 345ms/step - loss: 1.5216 - acc: 0.5292 - val_loss: 1.5444 - val_acc: 0.5257\n",
            "\n",
            "Epoch 00008: loss improved from 1.55211 to 1.51687, saving model to weights-improvement-08-1.5169.hdf5\n",
            "Epoch 9/10\n",
            "1133/1133 [==============================] - 390s 344ms/step - loss: 1.4843 - acc: 0.5405 - val_loss: 1.5313 - val_acc: 0.5298\n",
            "\n",
            "Epoch 00009: loss improved from 1.51687 to 1.48737, saving model to weights-improvement-09-1.4874.hdf5\n",
            "Epoch 10/10\n",
            "1133/1133 [==============================] - 390s 344ms/step - loss: 1.4684 - acc: 0.5424 - val_loss: 1.5222 - val_acc: 0.5346\n",
            "\n",
            "Epoch 00010: loss improved from 1.48737 to 1.46299, saving model to weights-improvement-10-1.4630.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzU-u1DP52FG",
        "outputId": "20820180-538f-4268-a405-ecfc102507fa"
      },
      "source": [
        "print(model.summary())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_3 (LSTM)                (None, 64)                23552     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 27)                1755      \n",
            "=================================================================\n",
            "Total params: 25,307\n",
            "Trainable params: 25,307\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KE7JDrvd5uW6",
        "outputId": "cc3a65e1-e988-4093-ae98-2b2f0ae2b9be"
      },
      "source": [
        "import random\n",
        "def random_generate(length):\n",
        "  index_list = [i for i in range(0,27)]\n",
        "  #pick a random index to start from our sentences list\n",
        "  start = np.random.randint(0, len(sentences)-1)\n",
        "  current_sen = sentences[start]\n",
        "  current = np.reshape(x[start],(1,50,27))\n",
        "  # print(current)\n",
        "  print(current_sen)\n",
        "  #pict the next char from the predicted distribution\n",
        "  for i in range(length):\n",
        "    # print(model.predict(current))\n",
        "    #choose according to the distribution\n",
        "    next_idx = random.choices(index_list, weights=model.predict(current)[0], k=1)[0]\n",
        "    \n",
        "    \n",
        "    next_char = i2c[next_idx]\n",
        "    print(next_char,end='')\n",
        "    current_sen += next_char\n",
        "    current_sen = current_sen[1:]\n",
        "\n",
        "    # convert sentence to our input by changing the last entry of current\n",
        "    temp = np.zeros((1,27), dtype=np.bool)\n",
        "    temp[0,c2i[next_char]] = 1\n",
        "    # print(temp)\n",
        "    # print(current.shape)\n",
        "    temp1 = np.append(current[0],temp,axis=0)\n",
        "    current[0] = np.delete(temp1,1,axis=0)\n",
        "\n",
        "#generate a sentence with 200 characters\n",
        "random_generate(200)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hen much surprised and interested on glancing down\n",
            " to care to keott mattersial and the craspired she of the some it alarr that the brights he seemed me had beated throught out your fortise car you is all fact of brive as instisting time when she conf"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_S1NJp5X484",
        "outputId": "ba44b951-b70f-4c71-8eea-15965d53af04"
      },
      "source": [
        "#to save the model\n",
        "!pip install pyyaml h5py  # Required to save models in HDF5 format"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (2.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from h5py) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4dJO_JYZLx1",
        "outputId": "684a5ef8-c814-4d50-eb76-4bf67ce6a74e"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPoR79vsYJhr",
        "outputId": "37083735-cc74-431f-db08-1a13872ad5eb"
      },
      "source": [
        "# Save the weights and model\n",
        "model.save_weights('./checkpoints/problem3')\n",
        "model.save('saved_model/problem3') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_10_layer_call_fn, lstm_cell_10_layer_call_and_return_conditional_losses, lstm_cell_11_layer_call_fn, lstm_cell_11_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_10_layer_call_fn, lstm_cell_10_layer_call_and_return_conditional_losses, lstm_cell_11_layer_call_fn, lstm_cell_11_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: saved_model/problem3/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: saved_model/problem3/assets\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}